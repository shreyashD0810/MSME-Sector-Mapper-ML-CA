{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "267d6982",
   "metadata": {},
   "source": [
    "Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e7d4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19400, 9)\n",
      "   LG_ST_Code        State  LG_DT_Code         District   Pincode  \\\n",
      "0          27  MAHARASHTRA         473       CHANDRAPUR  442502.0   \n",
      "1          27  MAHARASHTRA         488        OSMANABAD  413504.0   \n",
      "2          27  MAHARASHTRA         483  MUMBAI SUBURBAN  400101.0   \n",
      "3          27  MAHARASHTRA         480         KOLHAPUR  416502.0   \n",
      "4          27  MAHARASHTRA         486        NANDURBAR  425409.0   \n",
      "\n",
      "  RegistrationDate             EnterpriseName  \\\n",
      "0       21/01/2021  ABDUL KADAR MAJEET SHEIKH   \n",
      "1       21/01/2021       AAPULUCKY COLLECTION   \n",
      "2       21/01/2021             MOMAI MATERIAL   \n",
      "3       21/01/2021             SAFALYA CLINIC   \n",
      "4       21/01/2021        SHEETAL ENTERPRISES   \n",
      "\n",
      "                                CommunicationAddress  \\\n",
      "0  WARD NO 3, AARAMACHIN, USGAON, WARD NO 3, NAKO...   \n",
      "1  -, TULJABHAVANI NAGAR, CHINCHPUR ROAD, -, BHOO...   \n",
      "2  ROOM NO.6, HASAN AMIN CHAWL, RAM NAGAR, ROOM N...   \n",
      "3  MAIN ROAD , KADGAON, MANCHEKAR BUILDING, MAIN ...   \n",
      "4  SHOP NO. 01, SAI PLAZA, SHAHADA ROAD, SHOP NO....   \n",
      "\n",
      "                                          Activities  \n",
      "0  [{\"NIC5DigitId\":\"49300\",\"Description\":\"Transpo...  \n",
      "1  [{\"NIC5DigitId\":\"14101\",\"Description\":\"Manufac...  \n",
      "2  [{\"NIC5DigitId\":\"14104\",\"Description\":\"Manufac...  \n",
      "3  [{\"NIC5DigitId\":\"86100\",\"Description\":\"Hospita...  \n",
      "4  [{\"NIC5DigitId\":\"31001\",\"Description\":\"Manufac...  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19400 entries, 0 to 19399\n",
      "Data columns (total 9 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   LG_ST_Code            19400 non-null  int64  \n",
      " 1   State                 19400 non-null  object \n",
      " 2   LG_DT_Code            19400 non-null  int64  \n",
      " 3   District              19400 non-null  object \n",
      " 4   Pincode               19398 non-null  float64\n",
      " 5   RegistrationDate      19400 non-null  object \n",
      " 6   EnterpriseName        19399 non-null  object \n",
      " 7   CommunicationAddress  19400 non-null  object \n",
      " 8   Activities            19367 non-null  object \n",
      "dtypes: float64(1), int64(2), object(6)\n",
      "memory usage: 1.3+ MB\n",
      "None\n",
      "0    [{\"NIC5DigitId\":\"49300\",\"Description\":\"Transpo...\n",
      "1    [{\"NIC5DigitId\":\"14101\",\"Description\":\"Manufac...\n",
      "2    [{\"NIC5DigitId\":\"14104\",\"Description\":\"Manufac...\n",
      "3    [{\"NIC5DigitId\":\"86100\",\"Description\":\"Hospita...\n",
      "4    [{\"NIC5DigitId\":\"31001\",\"Description\":\"Manufac...\n",
      "Name: Activities, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(f\"E:\\ML proj\\Data\\msme_MAHARASHTRA.csv\")\n",
    "\n",
    "# Check basic info\n",
    "print(df.shape)\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df['Activities'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83b9c02",
   "metadata": {},
   "source": [
    "Filter Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bd06e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              EnterpriseName  \\\n",
      "0  ABDUL KADAR MAJEET SHEIKH   \n",
      "1       AAPULUCKY COLLECTION   \n",
      "2             MOMAI MATERIAL   \n",
      "3             SAFALYA CLINIC   \n",
      "4        SHEETAL ENTERPRISES   \n",
      "\n",
      "                                 ActivityDescription NIC5DigitId  \n",
      "0                             Transport via pipeline       49300  \n",
      "1  Manufacture of all types of textile garments a...       14101  \n",
      "2  Manufacture of wearing apparel made of leather...       14104  \n",
      "3                                Hospital activities       86100  \n",
      "4  Manufacture of furniture made of wood Manufact...       31001  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19400 entries, 0 to 19399\n",
      "Data columns (total 3 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   EnterpriseName       19399 non-null  object\n",
      " 1   ActivityDescription  19400 non-null  object\n",
      " 2   NIC5DigitId          19367 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 454.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def extract_activity_info(activity_str):\n",
    "    try:\n",
    "        if pd.isna(activity_str) or activity_str.strip() == \"\":\n",
    "            return \"\", None\n",
    "        activity_list = json.loads(activity_str)  # Use json.loads\n",
    "        descriptions = [d.get('Description', '') for d in activity_list]\n",
    "        nic_codes = [d.get('NIC5DigitId', '') for d in activity_list]\n",
    "        return \" \".join(descriptions), nic_codes[0] if nic_codes else None\n",
    "    except:\n",
    "        return \"\", None\n",
    "\n",
    "\n",
    "# Apply extraction\n",
    "df[['ActivityDescription', 'NIC5DigitId']] = df['Activities'].apply(lambda x: pd.Series(extract_activity_info(x)))\n",
    "\n",
    "# Now keep only relevant columns\n",
    "df = df[['EnterpriseName', 'ActivityDescription', 'NIC5DigitId']]\n",
    "\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35972ee",
   "metadata": {},
   "source": [
    "Missing Values handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7d434ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EnterpriseName          1\n",
      "ActivityDescription     0\n",
      "NIC5DigitId            33\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "After Cleaning: \n",
      "EnterpriseName         0\n",
      "ActivityDescription    0\n",
      "NIC5DigitId            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isna().sum())\n",
    "df = df.dropna(subset=['NIC5DigitId'])\n",
    "df['EnterpriseName'] = df['EnterpriseName'].fillna(\"\")\n",
    "df['ActivityDescription'] = df['ActivityDescription'].fillna(\"\")\n",
    "print(f\"\\n\\nAfter Cleaning: \\n{df.isna().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efde478c",
   "metadata": {},
   "source": [
    "Merge Text Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7a44b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df['EnterpriseName'] + \" \" + df['ActivityDescription']\n",
    "df = df[['Text', 'NIC5DigitId']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f220fece",
   "metadata": {},
   "source": [
    "Clean & Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "576586e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # lowercase\n",
    "    text = re.sub(r'\\d+', ' ', text)  # remove numbers\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)  # remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text)  # remove extra whitespace\n",
    "    # Lemmatize\n",
    "    text = \" \".join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "df['CleanText'] = df['Text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e38bd64",
   "metadata": {},
   "source": [
    "Encode Target Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45c1f49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['Label'] = le.fit_transform(df['NIC5DigitId'])\n",
    "\n",
    "# Save mapping for inference\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bbe9021",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = df['Label'].value_counts()\n",
    "rare_classes = class_counts[class_counts < 10].index\n",
    "df = df[~df['Label'].isin(rare_classes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1e50b9",
   "metadata": {},
   "source": [
    "Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d47c7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['CleanText']\n",
    "y = df['Label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98b0b2b",
   "metadata": {},
   "source": [
    "Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71123a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=20000, ngram_range=(1,2))\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7254458d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shrey\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "train_encodings = tokenizer(list(X_train), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(list(X_test), truncation=True, padding=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f0c21a",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cdf35b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Accuracy: 0.9176, F1-score: 0.9119, MSE: 5954.1907, MAE: 14.1267, RMSE: 77.1634\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train_tfidf, y_train)\n",
    "y_pred_lr = lr.predict(X_test_tfidf)\n",
    "\n",
    "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
    "f1_lr = f1_score(y_test, y_pred_lr, average='weighted')\n",
    "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "rmse_lr = np.sqrt(mse_lr)\n",
    "\n",
    "print(\"Logistic Regression:\")\n",
    "print(f\"Accuracy: {acc_lr:.4f}, F1-score: {f1_lr:.4f}, MSE: {mse_lr:.4f}, MAE: {mae_lr:.4f}, RMSE: {rmse_lr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc9a7677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "Accuracy: 0.9340, F1-score: 0.9303, MSE: 5365.4493, MAE: 12.4885, RMSE: 73.2492\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf.fit(X_train_tfidf, y_train)\n",
    "y_pred_rf = rf.predict(X_test_tfidf)\n",
    "\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "rmse_rf = np.sqrt(mse_rf)\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "print(f\"Accuracy: {acc_rf:.4f}, F1-score: {f1_rf:.4f}, MSE: {mse_rf:.4f}, MAE: {mae_rf:.4f}, RMSE: {rmse_rf:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03654cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM:\n",
      "Accuracy: 0.9533, F1-score: 0.9529, MSE: 4715.1950, MAE: 10.3828, RMSE: 68.6673\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm = LinearSVC(max_iter=5000)\n",
    "svm.fit(X_train_tfidf, y_train)\n",
    "y_pred_svm = svm.predict(X_test_tfidf)\n",
    "\n",
    "acc_svm = accuracy_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "mse_svm = mean_squared_error(y_test, y_pred_svm)\n",
    "mae_svm = mean_absolute_error(y_test, y_pred_svm)\n",
    "rmse_svm = np.sqrt(mse_svm)\n",
    "\n",
    "print(\"SVM:\")\n",
    "print(f\"Accuracy: {acc_svm:.4f}, F1-score: {f1_svm:.4f}, MSE: {mse_svm:.4f}, MAE: {mae_svm:.4f}, RMSE: {rmse_svm:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dc36020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model  Accuracy  F1-score          MSE        MAE       RMSE\n",
      "0  Logistic Regression  0.917627  0.911912  5954.190668  14.126728  77.163402\n",
      "1        Random Forest  0.934044  0.930309  5365.449309  12.488479  73.249227\n",
      "2                  SVM  0.953341  0.952916  4715.194988  10.382776  68.667277\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"Logistic Regression\", \"Random Forest\", \"SVM\"],\n",
    "    \"Accuracy\": [acc_lr, acc_rf, acc_svm],\n",
    "    \"F1-score\": [f1_lr, f1_rf, f1_svm],\n",
    "    \"MSE\": [mse_lr, mse_rf, mse_svm],\n",
    "    \"MAE\": [mae_lr, mae_rf, mae_svm],\n",
    "    \"RMSE\": [rmse_lr, rmse_rf, rmse_svm]\n",
    "})\n",
    "\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170ed75e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
